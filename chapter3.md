# 第三章 线性模型

## 3.1 基本形式

先讨论回归任务，再讨论二分类和多分类任务


## 3.2 线性回归

输入的属性： 
* 连续值
* 有序离散值 将其连续化转变为连续值
* 无序离散值 有k个属性就将其转换为k维向量  正交

一个变量的情况下就是最小二乘法。

多个变量的情况下就是多元线性回归，实际情况下变量的数目要远远多于样本的数目，此时引入**正则化项(6.4\11.4)**

在线性模型的基础上可以将y变为 **g(y)** ：广义线性模型，g(.)称为联系函数

## 3.3 对数几率回归

分类任务：找一个单调可微函数(分段函数？)将分类任务的真实标记y与线性回归模型的预测值联系起来

二分类任务将线性回归的实值z转换为0/1：单位阶跃函数，一般在实际应用中选择对数几率函数：*y = 1 / (1 + e ^ (- z))* ，将z值转化为一个接近0或者1的y值，并且在z=0附件变化很小

把对数几率函数看做是广义线性模型中的联系函数g(.)，用线性模型的结果去逼近真实标记的对数几率，此时任务变为估计出w和b

## 3.4 线性判别分析

LDA，Fisher判别分析：将样例投影到一条直线上，根据投影点的位置确定样本的类别

目标就要求将同一类别之间投影后样本间距离最小，不同类别之间距离最大。表征样本内距离：类内散度矩阵，用同类投影点的协方差表示；类间散度矩阵：用不同类矩阵的二范数平方表示(二范数可以表示距离)，最后求解此目标的问题可以变为一个求解类间散度矩阵和类内散度矩阵的广义瑞利商问题(p61)

[线性判别分析LDA原理总结]http://www.cnblogs.com/pinard/p/6244265.html 广义瑞利商，可以参考一下

LDA可以由二维情况推广至多分类情况

LDA也可以看做监督降维技术

注意LDA降维与PCA降维的区别和优劣

## 3.5 多分类问题

利用二分类学习器来解决多分类问题：

将多分类任务拆分为若干个二分类任务求解：对问题进行拆分，然后为每个二分类任务训练一个分类器，再测试时，对这些分类器的预测结果进行集成以获得最终的多分类结果

拆分策略：一对一OvO，一对其余OvR，多对多MvM *p64*

## 3.6 类别不平衡问题

不同类别的样本数量相差很大：需考察分类器的决策过程，再缩放

* 欠采样(下采用)：去除一些反例使正、反例数目解决再进行学习 代表算法：EasyEnsemble
* 过采样(上采样)：增加一些正例使正反例数目接近  代表算法：SMOTE
* 阈值移动：直接使用原始训练集进行学习，但是预测的时候加上正例除以反例使得阈值发生变化




